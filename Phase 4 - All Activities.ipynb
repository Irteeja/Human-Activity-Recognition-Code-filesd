{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e19ef0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('combined_dataset.csv')  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "674c931e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Mean Abs Diff</th>\n",
       "      <th>Mean Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>FFT Mean Coefficient</th>\n",
       "      <th>Power Bandwidth</th>\n",
       "      <th>Spectral Centroid</th>\n",
       "      <th>Spectral Distance</th>\n",
       "      <th>Spectral Entropy</th>\n",
       "      <th>Spectral Kurtosis</th>\n",
       "      <th>Spectral Skewness</th>\n",
       "      <th>Spectral Slope</th>\n",
       "      <th>Spectral Variation</th>\n",
       "      <th>Wavelet Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2_Subjects_1_Walking_1_Sitting</td>\n",
       "      <td>1.668911</td>\n",
       "      <td>1.590478</td>\n",
       "      <td>0.568368</td>\n",
       "      <td>0.342040</td>\n",
       "      <td>3.205999</td>\n",
       "      <td>-0.168249</td>\n",
       "      <td>0.383107</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>...</td>\n",
       "      <td>7.669400</td>\n",
       "      <td>5.962543</td>\n",
       "      <td>0.050829</td>\n",
       "      <td>9022.397389</td>\n",
       "      <td>-98173.400962</td>\n",
       "      <td>697.761196</td>\n",
       "      <td>24.583415</td>\n",
       "      <td>0.020192</td>\n",
       "      <td>7.866713</td>\n",
       "      <td>3698.886835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_Subjects_1_Walking_1_Sitting</td>\n",
       "      <td>1.906570</td>\n",
       "      <td>2.234498</td>\n",
       "      <td>0.854424</td>\n",
       "      <td>0.046754</td>\n",
       "      <td>3.196438</td>\n",
       "      <td>-1.409157</td>\n",
       "      <td>-0.300609</td>\n",
       "      <td>0.026576</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>...</td>\n",
       "      <td>8.759015</td>\n",
       "      <td>6.640120</td>\n",
       "      <td>0.056928</td>\n",
       "      <td>10447.319409</td>\n",
       "      <td>-116190.942776</td>\n",
       "      <td>641.621636</td>\n",
       "      <td>23.718316</td>\n",
       "      <td>0.023482</td>\n",
       "      <td>8.167360</td>\n",
       "      <td>5194.409887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_Subjects_1_Walking_1_Sitting</td>\n",
       "      <td>2.252619</td>\n",
       "      <td>2.269735</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>0.987268</td>\n",
       "      <td>3.438770</td>\n",
       "      <td>-0.907615</td>\n",
       "      <td>-0.167405</td>\n",
       "      <td>0.028942</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>...</td>\n",
       "      <td>10.054981</td>\n",
       "      <td>7.841932</td>\n",
       "      <td>0.056862</td>\n",
       "      <td>11242.782137</td>\n",
       "      <td>-134850.058838</td>\n",
       "      <td>742.813666</td>\n",
       "      <td>25.241097</td>\n",
       "      <td>0.028766</td>\n",
       "      <td>7.878008</td>\n",
       "      <td>6375.837418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_Subjects_1_Walking_1_Sitting</td>\n",
       "      <td>1.678924</td>\n",
       "      <td>1.514879</td>\n",
       "      <td>0.474886</td>\n",
       "      <td>0.864796</td>\n",
       "      <td>3.056379</td>\n",
       "      <td>-0.501180</td>\n",
       "      <td>0.725363</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>...</td>\n",
       "      <td>7.603583</td>\n",
       "      <td>5.993068</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>9166.397161</td>\n",
       "      <td>-95412.956751</td>\n",
       "      <td>742.682051</td>\n",
       "      <td>25.556531</td>\n",
       "      <td>0.021561</td>\n",
       "      <td>7.852462</td>\n",
       "      <td>3622.721992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_Subjects_1_Walking_1_Sitting</td>\n",
       "      <td>1.506674</td>\n",
       "      <td>1.594295</td>\n",
       "      <td>0.671808</td>\n",
       "      <td>0.081551</td>\n",
       "      <td>2.833673</td>\n",
       "      <td>-1.125067</td>\n",
       "      <td>-0.066780</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>...</td>\n",
       "      <td>6.859834</td>\n",
       "      <td>5.395679</td>\n",
       "      <td>0.047686</td>\n",
       "      <td>7311.965728</td>\n",
       "      <td>-88486.235573</td>\n",
       "      <td>638.180345</td>\n",
       "      <td>23.549291</td>\n",
       "      <td>0.018760</td>\n",
       "      <td>8.235253</td>\n",
       "      <td>3238.456485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37312</th>\n",
       "      <td>2_Subjects_Standing</td>\n",
       "      <td>1.465895</td>\n",
       "      <td>1.291933</td>\n",
       "      <td>0.709219</td>\n",
       "      <td>0.552888</td>\n",
       "      <td>3.252971</td>\n",
       "      <td>-0.592169</td>\n",
       "      <td>0.782573</td>\n",
       "      <td>0.014215</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>...</td>\n",
       "      <td>5.314844</td>\n",
       "      <td>4.319793</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>5235.116372</td>\n",
       "      <td>-74320.216322</td>\n",
       "      <td>597.475631</td>\n",
       "      <td>23.123594</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>10.214287</td>\n",
       "      <td>2975.363022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37313</th>\n",
       "      <td>2_Subjects_Standing</td>\n",
       "      <td>1.198803</td>\n",
       "      <td>0.772062</td>\n",
       "      <td>0.795964</td>\n",
       "      <td>0.079376</td>\n",
       "      <td>3.281201</td>\n",
       "      <td>-0.325113</td>\n",
       "      <td>1.067984</td>\n",
       "      <td>0.029003</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>...</td>\n",
       "      <td>5.754399</td>\n",
       "      <td>4.340771</td>\n",
       "      <td>0.046255</td>\n",
       "      <td>5239.978171</td>\n",
       "      <td>-74492.791875</td>\n",
       "      <td>469.628871</td>\n",
       "      <td>20.175301</td>\n",
       "      <td>0.014250</td>\n",
       "      <td>8.316423</td>\n",
       "      <td>2323.311489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37314</th>\n",
       "      <td>2_Subjects_Standing</td>\n",
       "      <td>1.380005</td>\n",
       "      <td>0.892549</td>\n",
       "      <td>0.915052</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>3.761951</td>\n",
       "      <td>-0.329486</td>\n",
       "      <td>1.066315</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>...</td>\n",
       "      <td>6.423546</td>\n",
       "      <td>5.329069</td>\n",
       "      <td>0.037011</td>\n",
       "      <td>5919.817871</td>\n",
       "      <td>-87927.735874</td>\n",
       "      <td>469.823184</td>\n",
       "      <td>20.178047</td>\n",
       "      <td>0.018598</td>\n",
       "      <td>8.576340</td>\n",
       "      <td>3076.227056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37315</th>\n",
       "      <td>2_Subjects_Standing</td>\n",
       "      <td>1.198811</td>\n",
       "      <td>0.775357</td>\n",
       "      <td>0.794906</td>\n",
       "      <td>0.063252</td>\n",
       "      <td>3.268007</td>\n",
       "      <td>-0.329486</td>\n",
       "      <td>1.066315</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>10.012724</td>\n",
       "      <td>8.854014</td>\n",
       "      <td>0.073857</td>\n",
       "      <td>15330.162384</td>\n",
       "      <td>-118523.197610</td>\n",
       "      <td>358.838771</td>\n",
       "      <td>15.973279</td>\n",
       "      <td>0.029142</td>\n",
       "      <td>4.706959</td>\n",
       "      <td>2321.442793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37316</th>\n",
       "      <td>2_Subjects_Standing</td>\n",
       "      <td>1.229323</td>\n",
       "      <td>0.831361</td>\n",
       "      <td>0.879194</td>\n",
       "      <td>0.048901</td>\n",
       "      <td>3.409592</td>\n",
       "      <td>-0.506215</td>\n",
       "      <td>0.920584</td>\n",
       "      <td>0.016485</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>...</td>\n",
       "      <td>5.863560</td>\n",
       "      <td>4.743952</td>\n",
       "      <td>0.038479</td>\n",
       "      <td>4290.210076</td>\n",
       "      <td>-78258.032660</td>\n",
       "      <td>465.988019</td>\n",
       "      <td>20.233548</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>8.575728</td>\n",
       "      <td>2562.891963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37317 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Label      Mean    Median   Std Dev       Min  \\\n",
       "0      2_Subjects_1_Walking_1_Sitting  1.668911  1.590478  0.568368  0.342040   \n",
       "1      2_Subjects_1_Walking_1_Sitting  1.906570  2.234498  0.854424  0.046754   \n",
       "2      2_Subjects_1_Walking_1_Sitting  2.252619  2.269735  0.532500  0.987268   \n",
       "3      2_Subjects_1_Walking_1_Sitting  1.678924  1.514879  0.474886  0.864796   \n",
       "4      2_Subjects_1_Walking_1_Sitting  1.506674  1.594295  0.671808  0.081551   \n",
       "...                               ...       ...       ...       ...       ...   \n",
       "37312             2_Subjects_Standing  1.465895  1.291933  0.709219  0.552888   \n",
       "37313             2_Subjects_Standing  1.198803  0.772062  0.795964  0.079376   \n",
       "37314             2_Subjects_Standing  1.380005  0.892549  0.915052  0.072812   \n",
       "37315             2_Subjects_Standing  1.198811  0.775357  0.794906  0.063252   \n",
       "37316             2_Subjects_Standing  1.229323  0.831361  0.879194  0.048901   \n",
       "\n",
       "            Max  Kurtosis  Skewness  Mean Abs Diff  Mean Diff  ...  \\\n",
       "0      3.205999 -0.168249  0.383107       0.029497   0.001279  ...   \n",
       "1      3.196438 -1.409157 -0.300609       0.026576   0.001249  ...   \n",
       "2      3.438770 -0.907615 -0.167405       0.028942   0.000392  ...   \n",
       "3      3.056379 -0.501180  0.725363       0.030810   0.000406  ...   \n",
       "4      2.833673 -1.125067 -0.066780       0.022624   0.000768  ...   \n",
       "...         ...       ...       ...            ...        ...  ...   \n",
       "37312  3.252971 -0.592169  0.782573       0.014215  -0.000073  ...   \n",
       "37313  3.281201 -0.325113  1.067984       0.029003   0.000186  ...   \n",
       "37314  3.761951 -0.329486  1.066315       0.017778   0.000147  ...   \n",
       "37315  3.268007 -0.329486  1.066315       0.020558  -0.000013  ...   \n",
       "37316  3.409592 -0.506215  0.920584       0.016485  -0.000877  ...   \n",
       "\n",
       "       FFT Mean Coefficient  Power Bandwidth  Spectral Centroid  \\\n",
       "0                  7.669400         5.962543           0.050829   \n",
       "1                  8.759015         6.640120           0.056928   \n",
       "2                 10.054981         7.841932           0.056862   \n",
       "3                  7.603583         5.993068           0.054496   \n",
       "4                  6.859834         5.395679           0.047686   \n",
       "...                     ...              ...                ...   \n",
       "37312              5.314844         4.319793           0.032929   \n",
       "37313              5.754399         4.340771           0.046255   \n",
       "37314              6.423546         5.329069           0.037011   \n",
       "37315             10.012724         8.854014           0.073857   \n",
       "37316              5.863560         4.743952           0.038479   \n",
       "\n",
       "       Spectral Distance  Spectral Entropy  Spectral Kurtosis  \\\n",
       "0            9022.397389     -98173.400962         697.761196   \n",
       "1           10447.319409    -116190.942776         641.621636   \n",
       "2           11242.782137    -134850.058838         742.813666   \n",
       "3            9166.397161     -95412.956751         742.682051   \n",
       "4            7311.965728     -88486.235573         638.180345   \n",
       "...                  ...               ...                ...   \n",
       "37312        5235.116372     -74320.216322         597.475631   \n",
       "37313        5239.978171     -74492.791875         469.628871   \n",
       "37314        5919.817871     -87927.735874         469.823184   \n",
       "37315       15330.162384    -118523.197610         358.838771   \n",
       "37316        4290.210076     -78258.032660         465.988019   \n",
       "\n",
       "       Spectral Skewness  Spectral Slope  Spectral Variation  Wavelet Energy  \n",
       "0              24.583415        0.020192            7.866713     3698.886835  \n",
       "1              23.718316        0.023482            8.167360     5194.409887  \n",
       "2              25.241097        0.028766            7.878008     6375.837418  \n",
       "3              25.556531        0.021561            7.852462     3622.721992  \n",
       "4              23.549291        0.018760            8.235253     3238.456485  \n",
       "...                  ...             ...                 ...             ...  \n",
       "37312          23.123594        0.015463           10.214287     2975.363022  \n",
       "37313          20.175301        0.014250            8.316423     2323.311489  \n",
       "37314          20.178047        0.018598            8.576340     3076.227056  \n",
       "37315          15.973279        0.029142            4.706959     2321.442793  \n",
       "37316          20.233548        0.015707            8.575728     2562.891963  \n",
       "\n",
       "[37317 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c6ad86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2_Subjects_1_Walking_1_Sitting',\n",
       "       '3_Subjects_2_Sitting_1_Standing', '3_Subjects_2_Sitting_1_Walk',\n",
       "       '1_Subject_Standing', '4_Subjects_Standing',\n",
       "       '4_Subjects_2_Sitting_2_Standing', '0_Subjects_Empty_Room',\n",
       "       '2_Subjects_1_Sitting_1_Standing', '2_Subjects_Sitting',\n",
       "       '3_Subjects_2_Standing_1_Sitting', '3_Subjects_Standing',\n",
       "       '3_Subjects_Sitting', '4_Subjects_Sitting', '1_Subject_Walking',\n",
       "       '1_Subject_Sitting', '2_Subjects_Standing'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed01d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    # 1-Subject group\n",
    "    '1_Subject_Sitting': '1-Subject',\n",
    "    '1_Subject_Standing': '1-Subject',\n",
    "    '1_Subject_Walking': '1-Subject',\n",
    "    # 2-Subject group\n",
    "    '2_Subjects_1_Sitting_1_Standing': '2-Subject',\n",
    "    '2_Subjects_1_Walking_1_Sitting': '2-Subject',\n",
    "    '2_Subjects_Sitting': '2-Subject',\n",
    "    '2_Subjects_Standing': '2-Subject',\n",
    "    # 3-Subject group\n",
    "    '3_Subjects_2_Sitting_1_Standing': '3-Subject',\n",
    "    '3_Subjects_2_Sitting_1_Walk': '3-Subject',\n",
    "    '13_Subjects_2_Standing_1_Sitting': '3-Subject',\n",
    "    '3_Subjects_Sitting': '3-Subject',\n",
    "    '3_Subjects_Standing': '3-Subject',\n",
    "    # 4-Subject group\n",
    "    '4_Subjects_2_Sitting_2_Standing': '4-Subject',\n",
    "    '4_Subjects_Sitting': '4-Subject',\n",
    "    '4_Subjects_Standing': '4-Subject',\n",
    "    # Empty remains unchanged\n",
    "    'Empty': 'Empty'\n",
    "}\n",
    " \n",
    "df['Label'] = df['Label'].map(label_mapping)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "658e8deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2-Subject', '3-Subject', '1-Subject', '4-Subject', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6365f4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Mean Abs Diff</th>\n",
       "      <th>Mean Diff</th>\n",
       "      <th>...</th>\n",
       "      <th>FFT Mean Coefficient</th>\n",
       "      <th>Power Bandwidth</th>\n",
       "      <th>Spectral Centroid</th>\n",
       "      <th>Spectral Distance</th>\n",
       "      <th>Spectral Entropy</th>\n",
       "      <th>Spectral Kurtosis</th>\n",
       "      <th>Spectral Skewness</th>\n",
       "      <th>Spectral Slope</th>\n",
       "      <th>Spectral Variation</th>\n",
       "      <th>Wavelet Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-Subject</td>\n",
       "      <td>1.668911</td>\n",
       "      <td>1.590478</td>\n",
       "      <td>0.568368</td>\n",
       "      <td>0.342040</td>\n",
       "      <td>3.205999</td>\n",
       "      <td>-0.168249</td>\n",
       "      <td>0.383107</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>...</td>\n",
       "      <td>7.669400</td>\n",
       "      <td>5.962543</td>\n",
       "      <td>0.050829</td>\n",
       "      <td>9022.397389</td>\n",
       "      <td>-98173.400962</td>\n",
       "      <td>697.761196</td>\n",
       "      <td>24.583415</td>\n",
       "      <td>0.020192</td>\n",
       "      <td>7.866713</td>\n",
       "      <td>3698.886835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-Subject</td>\n",
       "      <td>1.906570</td>\n",
       "      <td>2.234498</td>\n",
       "      <td>0.854424</td>\n",
       "      <td>0.046754</td>\n",
       "      <td>3.196438</td>\n",
       "      <td>-1.409157</td>\n",
       "      <td>-0.300609</td>\n",
       "      <td>0.026576</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>...</td>\n",
       "      <td>8.759015</td>\n",
       "      <td>6.640120</td>\n",
       "      <td>0.056928</td>\n",
       "      <td>10447.319409</td>\n",
       "      <td>-116190.942776</td>\n",
       "      <td>641.621636</td>\n",
       "      <td>23.718316</td>\n",
       "      <td>0.023482</td>\n",
       "      <td>8.167360</td>\n",
       "      <td>5194.409887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-Subject</td>\n",
       "      <td>2.252619</td>\n",
       "      <td>2.269735</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>0.987268</td>\n",
       "      <td>3.438770</td>\n",
       "      <td>-0.907615</td>\n",
       "      <td>-0.167405</td>\n",
       "      <td>0.028942</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>...</td>\n",
       "      <td>10.054981</td>\n",
       "      <td>7.841932</td>\n",
       "      <td>0.056862</td>\n",
       "      <td>11242.782137</td>\n",
       "      <td>-134850.058838</td>\n",
       "      <td>742.813666</td>\n",
       "      <td>25.241097</td>\n",
       "      <td>0.028766</td>\n",
       "      <td>7.878008</td>\n",
       "      <td>6375.837418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-Subject</td>\n",
       "      <td>1.678924</td>\n",
       "      <td>1.514879</td>\n",
       "      <td>0.474886</td>\n",
       "      <td>0.864796</td>\n",
       "      <td>3.056379</td>\n",
       "      <td>-0.501180</td>\n",
       "      <td>0.725363</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>...</td>\n",
       "      <td>7.603583</td>\n",
       "      <td>5.993068</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>9166.397161</td>\n",
       "      <td>-95412.956751</td>\n",
       "      <td>742.682051</td>\n",
       "      <td>25.556531</td>\n",
       "      <td>0.021561</td>\n",
       "      <td>7.852462</td>\n",
       "      <td>3622.721992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-Subject</td>\n",
       "      <td>1.506674</td>\n",
       "      <td>1.594295</td>\n",
       "      <td>0.671808</td>\n",
       "      <td>0.081551</td>\n",
       "      <td>2.833673</td>\n",
       "      <td>-1.125067</td>\n",
       "      <td>-0.066780</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>...</td>\n",
       "      <td>6.859834</td>\n",
       "      <td>5.395679</td>\n",
       "      <td>0.047686</td>\n",
       "      <td>7311.965728</td>\n",
       "      <td>-88486.235573</td>\n",
       "      <td>638.180345</td>\n",
       "      <td>23.549291</td>\n",
       "      <td>0.018760</td>\n",
       "      <td>8.235253</td>\n",
       "      <td>3238.456485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37312</th>\n",
       "      <td>2-Subject</td>\n",
       "      <td>1.465895</td>\n",
       "      <td>1.291933</td>\n",
       "      <td>0.709219</td>\n",
       "      <td>0.552888</td>\n",
       "      <td>3.252971</td>\n",
       "      <td>-0.592169</td>\n",
       "      <td>0.782573</td>\n",
       "      <td>0.014215</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>...</td>\n",
       "      <td>5.314844</td>\n",
       "      <td>4.319793</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>5235.116372</td>\n",
       "      <td>-74320.216322</td>\n",
       "      <td>597.475631</td>\n",
       "      <td>23.123594</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>10.214287</td>\n",
       "      <td>2975.363022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37313</th>\n",
       "      <td>2-Subject</td>\n",
       "      <td>1.198803</td>\n",
       "      <td>0.772062</td>\n",
       "      <td>0.795964</td>\n",
       "      <td>0.079376</td>\n",
       "      <td>3.281201</td>\n",
       "      <td>-0.325113</td>\n",
       "      <td>1.067984</td>\n",
       "      <td>0.029003</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>...</td>\n",
       "      <td>5.754399</td>\n",
       "      <td>4.340771</td>\n",
       "      <td>0.046255</td>\n",
       "      <td>5239.978171</td>\n",
       "      <td>-74492.791875</td>\n",
       "      <td>469.628871</td>\n",
       "      <td>20.175301</td>\n",
       "      <td>0.014250</td>\n",
       "      <td>8.316423</td>\n",
       "      <td>2323.311489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37314</th>\n",
       "      <td>2-Subject</td>\n",
       "      <td>1.380005</td>\n",
       "      <td>0.892549</td>\n",
       "      <td>0.915052</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>3.761951</td>\n",
       "      <td>-0.329486</td>\n",
       "      <td>1.066315</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>...</td>\n",
       "      <td>6.423546</td>\n",
       "      <td>5.329069</td>\n",
       "      <td>0.037011</td>\n",
       "      <td>5919.817871</td>\n",
       "      <td>-87927.735874</td>\n",
       "      <td>469.823184</td>\n",
       "      <td>20.178047</td>\n",
       "      <td>0.018598</td>\n",
       "      <td>8.576340</td>\n",
       "      <td>3076.227056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37315</th>\n",
       "      <td>2-Subject</td>\n",
       "      <td>1.198811</td>\n",
       "      <td>0.775357</td>\n",
       "      <td>0.794906</td>\n",
       "      <td>0.063252</td>\n",
       "      <td>3.268007</td>\n",
       "      <td>-0.329486</td>\n",
       "      <td>1.066315</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>10.012724</td>\n",
       "      <td>8.854014</td>\n",
       "      <td>0.073857</td>\n",
       "      <td>15330.162384</td>\n",
       "      <td>-118523.197610</td>\n",
       "      <td>358.838771</td>\n",
       "      <td>15.973279</td>\n",
       "      <td>0.029142</td>\n",
       "      <td>4.706959</td>\n",
       "      <td>2321.442793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37316</th>\n",
       "      <td>2-Subject</td>\n",
       "      <td>1.229323</td>\n",
       "      <td>0.831361</td>\n",
       "      <td>0.879194</td>\n",
       "      <td>0.048901</td>\n",
       "      <td>3.409592</td>\n",
       "      <td>-0.506215</td>\n",
       "      <td>0.920584</td>\n",
       "      <td>0.016485</td>\n",
       "      <td>-0.000877</td>\n",
       "      <td>...</td>\n",
       "      <td>5.863560</td>\n",
       "      <td>4.743952</td>\n",
       "      <td>0.038479</td>\n",
       "      <td>4290.210076</td>\n",
       "      <td>-78258.032660</td>\n",
       "      <td>465.988019</td>\n",
       "      <td>20.233548</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>8.575728</td>\n",
       "      <td>2562.891963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37317 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Label      Mean    Median   Std Dev       Min       Max  Kurtosis  \\\n",
       "0      2-Subject  1.668911  1.590478  0.568368  0.342040  3.205999 -0.168249   \n",
       "1      2-Subject  1.906570  2.234498  0.854424  0.046754  3.196438 -1.409157   \n",
       "2      2-Subject  2.252619  2.269735  0.532500  0.987268  3.438770 -0.907615   \n",
       "3      2-Subject  1.678924  1.514879  0.474886  0.864796  3.056379 -0.501180   \n",
       "4      2-Subject  1.506674  1.594295  0.671808  0.081551  2.833673 -1.125067   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "37312  2-Subject  1.465895  1.291933  0.709219  0.552888  3.252971 -0.592169   \n",
       "37313  2-Subject  1.198803  0.772062  0.795964  0.079376  3.281201 -0.325113   \n",
       "37314  2-Subject  1.380005  0.892549  0.915052  0.072812  3.761951 -0.329486   \n",
       "37315  2-Subject  1.198811  0.775357  0.794906  0.063252  3.268007 -0.329486   \n",
       "37316  2-Subject  1.229323  0.831361  0.879194  0.048901  3.409592 -0.506215   \n",
       "\n",
       "       Skewness  Mean Abs Diff  Mean Diff  ...  FFT Mean Coefficient  \\\n",
       "0      0.383107       0.029497   0.001279  ...              7.669400   \n",
       "1     -0.300609       0.026576   0.001249  ...              8.759015   \n",
       "2     -0.167405       0.028942   0.000392  ...             10.054981   \n",
       "3      0.725363       0.030810   0.000406  ...              7.603583   \n",
       "4     -0.066780       0.022624   0.000768  ...              6.859834   \n",
       "...         ...            ...        ...  ...                   ...   \n",
       "37312  0.782573       0.014215  -0.000073  ...              5.314844   \n",
       "37313  1.067984       0.029003   0.000186  ...              5.754399   \n",
       "37314  1.066315       0.017778   0.000147  ...              6.423546   \n",
       "37315  1.066315       0.020558  -0.000013  ...             10.012724   \n",
       "37316  0.920584       0.016485  -0.000877  ...              5.863560   \n",
       "\n",
       "       Power Bandwidth  Spectral Centroid  Spectral Distance  \\\n",
       "0             5.962543           0.050829        9022.397389   \n",
       "1             6.640120           0.056928       10447.319409   \n",
       "2             7.841932           0.056862       11242.782137   \n",
       "3             5.993068           0.054496        9166.397161   \n",
       "4             5.395679           0.047686        7311.965728   \n",
       "...                ...                ...                ...   \n",
       "37312         4.319793           0.032929        5235.116372   \n",
       "37313         4.340771           0.046255        5239.978171   \n",
       "37314         5.329069           0.037011        5919.817871   \n",
       "37315         8.854014           0.073857       15330.162384   \n",
       "37316         4.743952           0.038479        4290.210076   \n",
       "\n",
       "       Spectral Entropy  Spectral Kurtosis  Spectral Skewness  Spectral Slope  \\\n",
       "0         -98173.400962         697.761196          24.583415        0.020192   \n",
       "1        -116190.942776         641.621636          23.718316        0.023482   \n",
       "2        -134850.058838         742.813666          25.241097        0.028766   \n",
       "3         -95412.956751         742.682051          25.556531        0.021561   \n",
       "4         -88486.235573         638.180345          23.549291        0.018760   \n",
       "...                 ...                ...                ...             ...   \n",
       "37312     -74320.216322         597.475631          23.123594        0.015463   \n",
       "37313     -74492.791875         469.628871          20.175301        0.014250   \n",
       "37314     -87927.735874         469.823184          20.178047        0.018598   \n",
       "37315    -118523.197610         358.838771          15.973279        0.029142   \n",
       "37316     -78258.032660         465.988019          20.233548        0.015707   \n",
       "\n",
       "       Spectral Variation  Wavelet Energy  \n",
       "0                7.866713     3698.886835  \n",
       "1                8.167360     5194.409887  \n",
       "2                7.878008     6375.837418  \n",
       "3                7.852462     3622.721992  \n",
       "4                8.235253     3238.456485  \n",
       "...                   ...             ...  \n",
       "37312           10.214287     2975.363022  \n",
       "37313            8.316423     2323.311489  \n",
       "37314            8.576340     3076.227056  \n",
       "37315            4.706959     2321.442793  \n",
       "37316            8.575728     2562.891963  \n",
       "\n",
       "[37317 rows x 35 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b61f4d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\ihian\\anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihian\\anaconda3\\lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 52ms/step - accuracy: 0.5933 - loss: 1.0418 - val_accuracy: 0.8014 - val_loss: 0.5039 - learning_rate: 0.0010\n",
      "Epoch 2/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 82ms/step - accuracy: 0.7902 - loss: 0.5385 - val_accuracy: 0.8376 - val_loss: 0.4182 - learning_rate: 0.0010\n",
      "Epoch 3/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 85ms/step - accuracy: 0.8566 - loss: 0.3709 - val_accuracy: 0.8800 - val_loss: 0.3224 - learning_rate: 0.0010\n",
      "Epoch 6/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 85ms/step - accuracy: 0.8702 - loss: 0.3422 - val_accuracy: 0.8896 - val_loss: 0.2756 - learning_rate: 0.0010\n",
      "Epoch 7/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 85ms/step - accuracy: 0.8912 - loss: 0.2938 - val_accuracy: 0.9094 - val_loss: 0.2602 - learning_rate: 0.0010\n",
      "Epoch 9/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 82ms/step - accuracy: 0.8987 - loss: 0.2689 - val_accuracy: 0.8968 - val_loss: 0.2839 - learning_rate: 0.0010\n",
      "Epoch 10/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 68ms/step - accuracy: 0.9014 - loss: 0.2644 - val_accuracy: 0.9110 - val_loss: 0.2266 - learning_rate: 0.0010\n",
      "Epoch 11/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 58ms/step - accuracy: 0.9097 - loss: 0.2445 - val_accuracy: 0.9017 - val_loss: 0.2485 - learning_rate: 0.0010\n",
      "Epoch 12/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 83ms/step - accuracy: 0.9342 - loss: 0.1773 - val_accuracy: 0.9360 - val_loss: 0.1803 - learning_rate: 0.0010\n",
      "Epoch 21/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 70ms/step - accuracy: 0.9405 - loss: 0.1592 - val_accuracy: 0.9368 - val_loss: 0.1763 - learning_rate: 0.0010\n",
      "Epoch 22/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 47ms/step - accuracy: 0.9513 - loss: 0.1307 - val_accuracy: 0.9512 - val_loss: 0.1540 - learning_rate: 5.0000e-04\n",
      "Epoch 23/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 58ms/step - accuracy: 0.9607 - loss: 0.1044 - val_accuracy: 0.9515 - val_loss: 0.1480 - learning_rate: 5.0000e-04\n",
      "Epoch 24/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 63ms/step - accuracy: 0.9639 - loss: 0.0975 - val_accuracy: 0.9528 - val_loss: 0.1529 - learning_rate: 5.0000e-04\n",
      "Epoch 25/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 69ms/step - accuracy: 0.9652 - loss: 0.0945 - val_accuracy: 0.9502 - val_loss: 0.1563 - learning_rate: 5.0000e-04\n",
      "Epoch 26/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 84ms/step - accuracy: 0.9880 - loss: 0.0325 - val_accuracy: 0.9660 - val_loss: 0.1646 - learning_rate: 1.0000e-04\n",
      "Epoch 39/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 70ms/step - accuracy: 0.9872 - loss: 0.0357 - val_accuracy: 0.9638 - val_loss: 0.1768 - learning_rate: 1.0000e-04\n",
      "Epoch 40/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 70ms/step - accuracy: 0.9872 - loss: 0.0327 - val_accuracy: 0.9636 - val_loss: 0.1721 - learning_rate: 1.0000e-04\n",
      "Epoch 41/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 81ms/step - accuracy: 0.9896 - loss: 0.0287 - val_accuracy: 0.9638 - val_loss: 0.1953 - learning_rate: 1.0000e-04\n",
      "Epoch 42/500\n",
      "\u001b[1m1050/1050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 83ms/step - accuracy: 0.9889 - loss: 0.0343 - val_accuracy: 0.9646 - val_loss: 0.1801 - learning_rate: 1.0000e-04\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.9554 - loss: 0.1944\n",
      "Fold 1 Validation Accuracy: 0.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihian\\anaconda3\\lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (32, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int32' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 124\u001b[0m\n\u001b[0;32m    122\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormalized Confusion Matrix - Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    123\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m--> 124\u001b[0m     class_report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report for Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mclass_report\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAverage accuracy across folds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(fold_accuracies)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2592\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2591\u001b[0m     longest_last_line_heading \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2592\u001b[0m     name_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2593\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(name_width, \u001b[38;5;28mlen\u001b[39m(longest_last_line_heading), digits)\n\u001b[0;32m   2594\u001b[0m     head_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m:>\u001b[39m\u001b[38;5;132;01m{width}\u001b[39;00m\u001b[38;5;124ms} \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:>9}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(headers)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2592\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2591\u001b[0m     longest_last_line_heading \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2592\u001b[0m     name_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m cn \u001b[38;5;129;01min\u001b[39;00m target_names)\n\u001b[0;32m   2593\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(name_width, \u001b[38;5;28mlen\u001b[39m(longest_last_line_heading), digits)\n\u001b[0;32m   2594\u001b[0m     head_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m:>\u001b[39m\u001b[38;5;132;01m{width}\u001b[39;00m\u001b[38;5;124ms} \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:>9}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(headers)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.int32' has no len()"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    " \n",
    "df2 = df\n",
    "label_encoder = LabelEncoder()\n",
    "df2['Label'] = label_encoder.fit_transform(df2['Label'])\n",
    " \n",
    "\n",
    "X = df2.iloc[:, 1:].values \n",
    "y = df2['Label'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_reshaped = X_scaled.reshape(-1, X_scaled.shape[1], 1)\n",
    "input_shape = (X_scaled.shape[1], 1)\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "n_splits = 10\n",
    "\n",
    "class VectorBasedRelativePositionEmbedding(layers.Layer):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.embedding = self.add_weight(\n",
    "            shape=(max_len, d_model),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "            name=\"rel_pos_embedding\"\n",
    "        )\n",
    " \n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        positions = tf.range(start=0, limit=seq_len, delta=1)\n",
    "        return x + tf.gather(self.embedding, positions)\n",
    " \n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout)(x, x) + x\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.Conv1D(ff_dim, 1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    return layers.Conv1D(inputs.shape[-1], 1)(x) + inputs\n",
    " \n",
    "def create_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(32, 3, activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Conv1D(64, 3, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Conv1D(128, 3, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Reshape((-1, 128))(x)\n",
    "    x = VectorBasedRelativePositionEmbedding(128)(x)\n",
    "    for _ in range(3):\n",
    "        x = transformer_encoder(x, 64, 4, 256, 0.1)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    " \n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "fold_accuracies = []\n",
    " \n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_reshaped)):\n",
    "    print(f\"\\nFold {fold+1}/{n_splits}\")\n",
    "    X_train, X_val = X_reshaped[train_idx], X_reshaped[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    model = create_model(input_shape, num_classes)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=500,\n",
    "        batch_size=32,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "            keras.callbacks.LearningRateScheduler(\n",
    "                lambda epoch: 1e-3 * (0.1 if epoch > 30 else 0.5 if epoch > 20 else 1)\n",
    "            )\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    " \n",
    "    _, accuracy = model.evaluate(X_val, y_val)\n",
    "    fold_accuracies.append(accuracy)  \n",
    "    print(f\"Fold {fold+1} Validation Accuracy: {accuracy:.4f}\")\n",
    "    y_pred_prob = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
    "    cm = confusion_matrix(y_val, y_pred_classes)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(\n",
    "        cm_normalized, \n",
    "        annot=True, \n",
    "        fmt='.2f', \n",
    "        cmap='Blues', \n",
    "        xticklabels=label_encoder.classes_,  \n",
    "        yticklabels=label_encoder.classes_   \n",
    "    )\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title(f'Normalized Confusion Matrix - Fold {fold + 1}')\n",
    "    plt.show()\n",
    "    class_report = classification_report(\n",
    "        y_val, \n",
    "        y_pred_classes, \n",
    "        target_names=label_encoder.classes_ \n",
    "    )\n",
    "    print(f\"Classification Report for Fold {fold + 1}:\\n{class_report}\")\n",
    " \n",
    "print(f\"\\nAverage accuracy across folds: {np.mean(fold_accuracies):.4f}\")\n",
    "print(f\"Standard deviation of accuracy: {np.std(fold_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4bc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
